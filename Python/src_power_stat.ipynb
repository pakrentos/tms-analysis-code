{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import mat73\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display as disp\n",
    "from os.path import basename\n",
    "import subprocess\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "# %config Completer.use_jedi = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def true_meshgrid(*arr):\n",
    "    if len(arr) == 1:\n",
    "        return np.array(arr[0])[:, None]\n",
    "    return np.swapaxes(np.array(np.meshgrid(*arr)), 1, 2).reshape(len(arr), -1).T\n",
    "\n",
    "import scipy.io as spio\n",
    "\n",
    "from matplotlib import transforms as mtrans\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "def transform_same_lines(ax_obj, fig, shift):\n",
    "    children = ax_obj.get_children()\n",
    "    colors = []\n",
    "    for i in children:\n",
    "        if not hasattr(i, 'get_color'):\n",
    "            colors.append('')\n",
    "            continue\n",
    "        \n",
    "        if isinstance(i.get_color(), str):\n",
    "            temp = i.get_color()\n",
    "        else:\n",
    "            temp = rgb2hex(i.get_color()[0])\n",
    "        \n",
    "        if temp[0] == '#':\n",
    "            colors.append(temp)\n",
    "        else:\n",
    "            colors.append('')\n",
    "    \n",
    "    colors_set = list(set(colors) ^ {''})\n",
    "    colors = np.array(colors)\n",
    "    children_arr = np.array(children)\n",
    "    \n",
    "    for ind, color in enumerate(colors_set):\n",
    "        temp = children_arr[colors==color].tolist()\n",
    "        tr = mtrans.offset_copy(ax_obj.transData, fig=fig, x=ind*shift, y=0., units='points')\n",
    "        for obj in temp: \n",
    "            obj.set_transform(tr)\n",
    "\n",
    "def _loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    ks = '__header__', '__version__', '__globals__'\n",
    "    for k in ks:\n",
    "        data.pop(k)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "        elif isinstance(dict[key], np.ndarray):\n",
    "            for ind, obj in enumerate(dict[key]):\n",
    "                dict[key][ind] = _todict(obj)\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _redefine(struct):\n",
    "    struct['label'] = np.squeeze(struct['label']).tolist()\n",
    "    time = struct['time']\n",
    "    trial = struct['trial']\n",
    "    lens = [t.shape[0] for t in time]\n",
    "    minlen = min(lens)\n",
    "    for ind, (ti, tr) in enumerate(zip(time, trial)):\n",
    "        struct['trial'][ind] = tr[..., :minlen]\n",
    "        struct['time'][ind] = ti[:minlen]\n",
    "    struct['time'] = np.array(np.array(struct['time']).tolist(), dtype=np.float64)\n",
    "    struct['trial'] = np.array(np.array(struct['trial']).tolist(), dtype=np.float64)\n",
    "\n",
    "def recursive_redefine(struct):\n",
    "    if isinstance(struct, list) or isinstance(struct, np.ndarray):\n",
    "        for obj in struct:\n",
    "            recursive_redefine(obj)\n",
    "    if isinstance(struct, dict):\n",
    "        if (struct.get('trial') is not None) and (struct.get('time') is not None) and (struct.get('fsample') is not None):\n",
    "            if isinstance(struct['time'], list):\n",
    "                _redefine(struct)\n",
    "            elif struct['trial'].dtype == np.object:\n",
    "                _redefine(struct)\n",
    "            \n",
    "            if len(struct['trial'].shape) == 2:\n",
    "                struct['trial'] = struct['trial'][np.newaxis, :, :]\n",
    "            \n",
    "            if len(struct['time'].shape) == 1:\n",
    "                struct['time'] = np.tile(struct['time'], (struct['trial'].shape[0], 1))\n",
    "\n",
    "        else:\n",
    "            for k, v in struct.items():\n",
    "                recursive_redefine(v)\n",
    "\n",
    "def loadmat(fname):\n",
    "    try:\n",
    "        return mat73.loadmat(fname)\n",
    "    except TypeError:\n",
    "        return _loadmat(fname)\n",
    "    \n",
    "def save_masked(name, arr):\n",
    "    temp = np.array(arr)\n",
    "    temp[arr.mask] *= np.nan\n",
    "    np.save(name, temp)\n",
    "    \n",
    "def load_masked(name):\n",
    "    temp = np.load(name)\n",
    "    return ma.array(temp, mask=np.isnan(temp))\n",
    "\n",
    "def norm(a):\n",
    "    return (a - np.nanmin(a))/(np.nanmax(a) - np.nanmin(a))\n",
    "    \n",
    "def local_mins(sig):\n",
    "    sig_len = sig.shape[-1]\n",
    "    local_min_points_mask = np.diff((np.diff(sig) < 0).astype(int)) < 0\n",
    "    local_min_points_inds = np.r_[2:sig_len][local_min_points_mask]\n",
    "    local_min_points_values = sig[local_min_points_inds]\n",
    "    return local_min_points_inds, local_min_points_values\n",
    "\n",
    "def local_maxes(sig):\n",
    "    sig_len = sig.shape[-1]\n",
    "    local_min_points_mask = np.diff((np.diff(sig) < 0).astype(int)) > 0\n",
    "    local_min_points_inds = np.r_[2:sig_len][local_min_points_mask]\n",
    "    local_min_points_values = sig[local_min_points_inds]\n",
    "    return local_min_points_inds, local_min_points_values\n",
    "\n",
    "import itertools\n",
    "\n",
    "def create_shape(obj, hard=False):\n",
    "    if hasattr(obj, '__len__'):\n",
    "        if len(obj) == 0:\n",
    "            return [0]\n",
    "        if not hard:\n",
    "            if not hasattr(obj[0], '__len__'):\n",
    "                return [len(obj)]\n",
    "        lens = [create_shape(i) for i in obj]\n",
    "        pure_lens = [i for i in lens if i is not None]\n",
    "        depths = []\n",
    "        if len(pure_lens) != 0:\n",
    "            depths = np.array(list(itertools.zip_longest(*pure_lens, fillvalue=0))).max(axis=-1).tolist()\n",
    "        obj_len = len(obj)\n",
    "        temp = [len(obj)] + depths\n",
    "        return [i for i in temp if i != 0]\n",
    "    \n",
    "def marray_from_lists(obj):\n",
    "    shape = np.array(create_shape(obj))\n",
    "#     print(shape)\n",
    "    ndims = len(shape)\n",
    "    if ndims == 1:\n",
    "        return ma.array(obj)\n",
    "    else:\n",
    "        return _marray_from_lists(obj, shape, 0)\n",
    "    \n",
    "def _marray_from_lists(obj, shape, depth):\n",
    "    ndims = len(shape)\n",
    "    if depth == ndims - 1:\n",
    "        if hasattr(obj, '__len__'):\n",
    "            pass # для учтения кейса\n",
    "        else:\n",
    "            if obj is not None:\n",
    "                obj = [obj]\n",
    "            else:\n",
    "                temp = ma.empty(shape[depth])\n",
    "                temp.mask = True\n",
    "                return temp\n",
    "        ntrail = shape[depth] - len(obj)\n",
    "        trail = ma.empty(ntrail)\n",
    "        trail.mask = True\n",
    "        temp = ma.array(obj)\n",
    "        return ma.concatenate((obj, trail))\n",
    "    else:\n",
    "        if not hasattr(obj, '__len__'):\n",
    "            temp = ma.empty(shape[depth:])\n",
    "            if obj is not None:\n",
    "                mask = np.ones(shape[depth:]).flatten()\n",
    "                temp = ma.empty(shape[depth:]).flatten()\n",
    "                mask[0] = 0\n",
    "                temp[0] = obj\n",
    "                temp.mask = mask\n",
    "                temp = temp.reshape(shape[depth:])\n",
    "            else:\n",
    "                temp.mask = True\n",
    "            return temp\n",
    "        else:\n",
    "            trail_shape = shape[depth:].copy()\n",
    "            trail_shape[0] -= len(obj)\n",
    "#             print(trail_shape, shape)\n",
    "            trail = ma.empty(trail_shape)\n",
    "            trail.mask = True\n",
    "            temp = ma.stack([_marray_from_lists(i, shape, depth + 1) for i in obj])\n",
    "            temp = ma.concatenate((temp, trail))\n",
    "            return temp\n",
    "        \n",
    "def allbut(*names, levels):\n",
    "    names = set(names)\n",
    "    return [item for item in levels if item not in names]\n",
    "\n",
    "def get_MANOVA_table(data, sub_f, factors, var_names):\n",
    "    if len(data.shape) != sub_f + 2:\n",
    "        data = data.copy()[..., None]\n",
    "    assert data.shape[-1] == len(var_names)\n",
    "    assert sub_f == len(factors.keys())\n",
    "    for i, v in enumerate(factors.values()):\n",
    "        assert data.shape[i] == len(v)\n",
    "    \n",
    "    sub_n = data.shape[sub_f]\n",
    "    subs = np.arange(1, sub_n + 1, dtype=int).tolist()\n",
    "    factors_raw = true_meshgrid(*([subs] + [v for v in factors.values()])).tolist()\n",
    "    factor_names = list(factors.keys())\n",
    "    cols = ['Subject'] + factor_names + var_names\n",
    "    \n",
    "    temp = np.rollaxis(data, sub_f).reshape(-1, len(var_names)).tolist()\n",
    "    \n",
    "    data_raw = [a + b for a,b in zip(factors_raw, temp)]\n",
    "    res_df = pd.DataFrame(data_raw, columns=cols)\n",
    "    return res_df\n",
    "\n",
    "def plot_jasp(data, x, line=None, plots=None, errors=True, var=None, kind='line', sharey=False, scale=(1, 1), inverse_orient=False):\n",
    "    limity = (None, None)\n",
    "    scalemin, scalemax = scale\n",
    "    if sharey:\n",
    "        limity = data.min().tolist()[-1]/scalemin, data.max().tolist()[-1]/scalemax\n",
    "    if plots is not None:\n",
    "        ngroups = data.groupby(plots).ngroups\n",
    "        cols = int(np.sqrt(ngroups))\n",
    "        rows = int(np.ceil(ngroups/cols))\n",
    "        if inverse_orient:\n",
    "            cols, rows = rows, cols\n",
    "        fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(6.4*cols, 4.8*rows))\n",
    "        axes = np.array(axes).flatten().tolist()\n",
    "        for (group_name, group), ax in zip(data.groupby(plots), axes):\n",
    "            group_name = [group_name] if not isinstance(group_name, tuple) else group_name\n",
    "            plots_list = [plots] if not hasattr(plots, '__iter__') else plots\n",
    "            title = '; '.join([': '.join(i) for i in zip(plots_list, group_name)])\n",
    "            _plot_jasp(group, x, line, title, ax=ax, errors=errors, kind=kind, sharey=limity, var=var)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        _plot_jasp(data, x, line, ax=ax, var=var)\n",
    "    return fig\n",
    "    \n",
    "    \n",
    "def _plot_jasp(data, x, line=None, title=None, subplots=False, ax=None, errors=True, kind='line', sharey=(None, None), var=None):\n",
    "    groups = [x]\n",
    "    groups.append(line) if line is not None else None\n",
    "    means = data.groupby(groups).mean().unstack(level=x).T.droplevel(0)\n",
    "    errors = data.groupby(groups).sem().unstack(level=x).T.droplevel(0) if errors else None\n",
    "    kwargs = {}\n",
    "    if errors is not None:\n",
    "        kwargs['capsize'] = 8\n",
    "    ax = means.plot(kind=kind, yerr=errors, title=title, ax=ax, ylim=sharey, **kwargs)\n",
    "    xticks = list(means.index)\n",
    "#     print(xticks)\n",
    "    if len(xticks) == 2:\n",
    "        ticks = ax.get_xticklabels()\n",
    "#         print(ticks)\n",
    "        ticks[-2].set_text(xticks[-1])\n",
    "        ax.set_xticklabels(ticks)\n",
    "#     print()\n",
    "    ax.grid()\n",
    "    fig = ax.figure\n",
    "    transform_same_lines(ax, fig, 10) if kind =='line' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNC Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "datas = {}\n",
    "norms = ['absolute', '1d', 'relative', 'relative1d']\n",
    "coef_types = ['ClustCoef', 'Eglob']\n",
    "exclude = {'__header__', '__version__', '__globals__'}\n",
    "table_labels = true_meshgrid(norms, coef_types)\n",
    "for norm, coef_type in table_labels:\n",
    "    print(norm, coef_type)\n",
    "    test = []\n",
    "    days = len(glob(f'data/fnc_{norm}_norm/{coef_type}*'))\n",
    "    for fname in glob(f'data/fnc_{norm}_norm/{coef_type}*'):\n",
    "        mat = spio.loadmat(fname)\n",
    "        field = list(set(mat.keys()) - exclude)[0]\n",
    "        for i in range(15):\n",
    "            if i == 9:\n",
    "                test += np.full(2*2*3*2*2, np.nan).tolist()\n",
    "                continue\n",
    "            for j in range(4):\n",
    "                for k in range(3):\n",
    "                    test += [i[0][0] for i in mat[field][i, j][0, 0][k][0][0]]\n",
    "\n",
    "    data = np.array(test).reshape(days,    15,   2,     2,        3,     2,      2)\n",
    "    #                            'day' 'sub' 'cond' 'session' 'band' 'zone', 'side'\n",
    "    days = [f'D{i+1}' for i in range(days)]\n",
    "    conds = ['Pre', 'Post']\n",
    "    sessions = ['Im1', 'Im2']\n",
    "    bands = ['Theta', 'Alpha', 'Beta']\n",
    "    zones = ['BA4', 'BA6']\n",
    "    sides = ['Left', 'Right']\n",
    "\n",
    "    labels = true_meshgrid(days, conds, sessions, bands, zones, sides)\n",
    "    labels_dict = {\n",
    "        'Day': days,\n",
    "        'Condition': ['Baseline', 'Post'],\n",
    "        'Session': sessions,\n",
    "        'Band': bands,\n",
    "        'Zone': zones,\n",
    "        'Side': sides,\n",
    "    }\n",
    "    # df = get_RM_ANOVA_table(data[:, :, :, ...], 1, labels)\n",
    "    # df.to_csv(f'tables/{coef_type}_{norm}_norm_TMS.csv', index=False)\n",
    "    temp_data = np.rollaxis(data[:, :, :, ...][..., None], 1, -1)\n",
    "    df = get_MANOVA_table(temp_data, 6, labels_dict, ['Coef'])\n",
    "    dfs[coef_type] = {} if dfs.get(coef_type) is None else dfs[coef_type]\n",
    "    dfs[coef_type][norm] = df.query(\"Subject != '10'\")\n",
    "    datas[coef_type] = {} if datas.get(coef_type) is None else datas[coef_type]\n",
    "    datas[coef_type][norm] = {'data': data, 'groups': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = sorted(glob('../power_sfr/ClustPow_Norm_by_1stDay/*'))\n",
    "# filenames = [basename(i) for i in files]\n",
    "# f = open(files[0])\n",
    "# data = np.stack([np.array([i.split() for i in open(file).readlines()]).astype(float) for file in files])\n",
    "# data[data == 0] = np.nan\n",
    "# data = data.reshape(2, 3, 2, 2, 15, 2, 2, 1)\n",
    "# data = np.transpose(data, [0, 1, 2, 3, 5, 6, 4, 7])\n",
    "# conds = {\n",
    "#     'Condition': ['Baseline', 'Post'],\n",
    "#     'Band': ['Alpha', 'Beta', 'Theta'],\n",
    "#     'Zone': ['BA4', 'BA6'],\n",
    "#     'Side': ['Left', 'Right'],\n",
    "#     'Day': ['D1', 'D2'],\n",
    "#     'Session': ['Im1', 'Im2']\n",
    "# }\n",
    "# tms_power = get_MANOVA_table(data, 6, conds, ['Power']).query('Subject != \"10\"')\n",
    "# tms_power.to_csv('../power_sfr/TMS_CLUST_POWER_1D_NORM.csv', index=False)\n",
    "tms_power = pd.read_csv('../power_sfr/TMS_CLUST_POWER_1D_NORM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms_power_old = pd.read_csv('../power_sfr/tms_all_ma.csv')\n",
    "tms_power_old['Zone'] = 'BA' + tms_power_old['Zone'].astype(str)\n",
    "tms_power_old['Subject'] = tms_power_old['Subject'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tms_power_old.set_index(['Subject', 'Side','Band', 'Zone', 'Day','Session']).query('Condition == \"Post\"').drop(columns='Condition').dropna()\n",
    "a = tms_power_old.set_index(['Subject', 'Side','Band', 'Zone', 'Day','Session']).query('Condition == \"Base\"').drop(columns='Condition').dropna()\n",
    "tms_count = a > b\n",
    "tms_count = tms_count.reset_index()\n",
    "tms_count = tms_count.groupby(['Side','Band', 'Zone', 'Day','Session']).mean().reset_index()\n",
    "\n",
    "\n",
    "# depvar = 'Power'\n",
    "# subject = 'Subject'\n",
    "# cols = list(set(tms_count.columns) - set([depvar, subject]))\n",
    "# res = AnovaRM(data=tms_count, depvar=depvar, subject=subject, within=cols, aggregate_func=np.mean).fit()\n",
    "# res_sum = res.summary().tables[0].query('`Pr > F` < 0.06')\n",
    "# disp(res_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms_count.query('Zone == \"BA6\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = sns.catplot(x='Session', y='Coef', hue='Day', col='Side', row='Band', data=dfs['ClustCoef']['absolute'].query('Zone == \"BA6\"'), kind='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test = pd.DataFrame()\n",
    "n = dfs['ClustCoef']['absolute']['Coef'].size\n",
    "labels = np.repeat(true_meshgrid(['Cluster coefficient', 'Eglob'], ['Absolute', 'Relative']), n, axis=0)\n",
    "clab = pd.DataFrame(labels[:1344], columns=['Type', 'Norm'])\n",
    "clre = pd.DataFrame(labels[1344:1344*2], columns=['Type', 'Norm'])\n",
    "egab = pd.DataFrame(labels[1344*2:1344*3], columns=['Type', 'Norm'])\n",
    "egre = pd.DataFrame(labels[1344*3:1344*4], columns=['Type', 'Norm'])\n",
    "pd.concat( [dfs['ClustCoef']['absolute'], clab], join='outer', )\n",
    "# a = dfs['ClustCoef']['absolute'].reset_index()['Coef'].to_numpy()\n",
    "# b = dfs['ClustCoef']['relative'].reset_index()['Coef'].to_numpy()\n",
    "# c = dfs['Eglob']['absolute'].reset_index()['Coef'].to_numpy()\n",
    "# d = dfs['Eglob']['relative'].reset_index()['Coef'].to_numpy()\n",
    "# test = np.stack([a, b, c, d]).reshape(2, 2, -1)\n",
    "# test = test.reshape(-1, 1)\n",
    "# test = np.hstack([labels, test])\n",
    "# test = pd.DataFrame(test, columns=['Coef', 'Norm', 'Value'])\n",
    "# test['Value'] = test['Value'].astype(float)\n",
    "\n",
    "# test['Value'] = dfs['ClustCoef']['absolute']['Coef'].reset_index()\n",
    "# test['Coefficient'] = 'Cluster coefficient'\n",
    "# test['Norm'] = 'Absolute'\n",
    "# test['Cluster Relative'] = dfs['ClustCoef']['relative']['Coef'].reset_index()\n",
    "# test['Eglob Absolute'] = dfs['Eglob']['absolute']['Coef'].reset_index()\n",
    "# test['Eglob Relative'] = dfs['Eglob']['relative']['Coef'].reset_index()\n",
    "# sns.displot(test, x=\"Value\", col='Coef', row='Norm', kind='kde', common_norm=False, facet_kws=dict(sharey=False, sharex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='Coef', data=dfs['ClustCoef']['absolute'], kind='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.catplot(x='Session', y='Coef', hue='Day', col='Side', row='Band', data=dfs['ClustCoef']['relative'].query('Zone == \"BA6\"'), kind='violin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms_power_old.query('Condition == \"Base\"').drop(columns='Condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(df):\n",
    "    return df.groupby(['Day', 'Session']).mean()[['Power']].unstack(level='Session').T.droplevel(0)\n",
    "tms_power.groupby(['Band']).apply(apply).plot(subplots=True)# .groupby(['Day', 'Session']).mean()[['Power']].unstack(level='Session').T.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms_power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tms_power.groupby(['Side', 'Zone', 'Day', 'Session']).mean()[['Power']].unstack(level=['Day', 'Session']).plot(subplots=True, rot=90, figsize=(9, 7), layout=(2, 2))\n",
    "import seaborn as sns\n",
    "a = tms_power.query('Day == \"D2\" and Session == \"Im2\" and Band == \"Alpha\"')\n",
    "b = tms_power.query('Day == \"D2\" and Session == \"Im1\" and Band == \"Alpha\"')\n",
    "sns.catplot(x='Condition', y='Power', hue='Subject', kind='point', data=a)\n",
    "sns.catplot(x='Condition', y='Power', hue='Subject', kind='point', data=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0])\n",
    "np.mean([1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tms_power\n",
    "col = data.columns[0]\n",
    "x = 'Session'\n",
    "line = 'Day'\n",
    "plots = ['Condition', 'Side', 'Band']\n",
    "# plots = None\n",
    "inverse_orient = True\n",
    "\n",
    "title = 'Side*Day*Session*Band Base'\n",
    "\n",
    "query = 'Condition == \"Baseline\"' #and Zone == \"BA6\" and Side == \"L\"'\n",
    "# query = f\"{col}.isnull() or {col}.notnull()\"\n",
    "fig = plot_jasp(data.query(query), x, line=line, plots=plots, sharey=False, scale=(8, 1000), inverse_orient=inverse_orient);\n",
    "# fig.tight_layout()\n",
    "fig.suptitle(title, fontsize=20)\n",
    "fig.savefig('temp.jpg')\n",
    "subprocess.run([\"osascript\", \"-e\", 'set the clipboard to (read (POSIX file \"temp.jpg\") as JPEG picture)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfs['Eglob']['absolute']\n",
    "depvar = 'Coef'\n",
    "subject = 'Subject'\n",
    "cols = list(set(data.columns) - set([depvar, subject]))\n",
    "res = AnovaRM(data=data, depvar=depvar, subject=subject, within=cols, aggregate_func=np.median).fit()\n",
    "res_sum = res.summary().tables[0].query('`Pr > F` < 0.06')\n",
    "disp(res_sum)\n",
    "# res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dfs['ClustCoef']['absolute']['Subject'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = postHocTtest(tms_power_old, depvar='Power', effects=['Side', 'Zone'], includes=['Day', 'Session', 'Band', 'Condition'], query=query, average_unused=True, agg='mean')\n",
    "# df.style.apply(lambda x: [f\"background-color: #00ff00{hex(int(255*v))[2:]}\" \n",
    "#                           if (i >= 1 and v < 0.05)\n",
    "#                           else \"\" for i, v in enumerate(x)], axis = 1)\n",
    "df.style.background_gradient(subset=['P value', 'Holmes corr'], cmap='Reds_r', vmin=0., vmax=0.1)\n",
    "# df.query(' < 0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = 'Zone == \"Condition == \"Post\"'\n",
    "query = None\n",
    "data = dfs['Eglob']['relative']\n",
    "depvar = 'Coef'\n",
    "# print(query)\n",
    "df = postHocTtest(data, depvar=depvar, effects=['Day', 'Session'], includes=['Band', 'Zone', 'Side', 'Condition'], query=query, average_unused=True, agg='mean')\n",
    "# df.style.apply(lambda x: [f\"background-color: #00ff00{hex(int(255*v))[2:]}\" \n",
    "#                           if (i >= 1 and v < 0.05)\n",
    "#                           else \"\" for i, v in enumerate(x)], axis = 1)\n",
    "df.query('`P value` < 0.0505').style.background_gradient(subset=['P value', 'Holmes corr'], cmap='Reds_r', vmin=0., vmax=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = None\n",
    "# print(query)\n",
    "df = postHocTtest(dfs['Eglob']['absolute'], depvar='Coef', effects=['Day', 'Session'], includes=['Band', 'Zone', 'Side', 'Condition'], query=query, average_unused=True, agg='mean')\n",
    "# df.style.apply(lambda x: [f\"background-color: #00ff00{hex(int(255*v))[2:]}\" \n",
    "#                           if (i >= 1 and v < 0.05)\n",
    "#                           else \"\" for i, v in enumerate(x)], axis = 1)\n",
    "df.style.background_gradient(subset=['P value', 'Holmes corr'], cmap='Reds_r', vmin=0., vmax=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import AnovaRM\n",
    "coef_type = 'ClustCoef'\n",
    "norm = 'relative'\n",
    "for coef_type in coef_types:\n",
    "    print(coef_type, norm)\n",
    "    data = dfs[coef_type][norm]\n",
    "    res = AnovaRM(data=data, depvar='Coef', subject='Subject', within=list(labels_dict.keys()), aggregate_func=np.mean).fit()\n",
    "    res_sum = res.summary().tables[0].query('`Pr > F` <= 0.05')\n",
    "    disp(res_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfs[\"ClustCoef\"]['relative']\n",
    "x = 'Session'\n",
    "line = 'Day'\n",
    "plots = ['Band']\n",
    "fig = plot_jasp(data.query('Condition == \"Post\"'), x, line=line, plots=plots, sharey=False, scale=(8, 1000));\n",
    "fig.tight_layout()\n",
    "# fig.savefig(f'TMS_{coef_type}_{norm}_@{x}_{line}_{\"_\".join(plots)}@.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress, combinations\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def unique_labels(df, columns):\n",
    "    df_columns = df.columns\n",
    "    assert isinstance(columns, list)\n",
    "    assert len(set(columns) - set(df_columns)) == 0, \"Missing columns\"\n",
    "    labels = [np.unique(i).tolist() for i in df[columns].to_numpy().T]\n",
    "    return {k:v for k, v in zip(columns, labels)}\n",
    "\n",
    "def holmes_correction(vals, crit=0.05):\n",
    "    inds = np.argsort(vals)\n",
    "    corr_mul = np.arange(len(vals))[::-1] + 1\n",
    "    return vals < crit/corr_mul[inds]\n",
    "\n",
    "def fdr(p_vals):\n",
    "    ranked_p_values = rankdata(p_vals)\n",
    "    fdr = p_vals * len(p_vals) / ranked_p_values\n",
    "    fdr[fdr > 1] = 1\n",
    "\n",
    "    return fdr\n",
    "\n",
    "def postHocTtest(df, depvar=None, subject='Subject', effects=None, includes=[], average_unused=True, query=None, agg = 'mean'):\n",
    "    temp = df.copy() if query is None else df.query(query)\n",
    "    columns = temp.columns\n",
    "    assert len(set(effects) - set(columns)) == 0, \"Missing effects\"\n",
    "    assert subject in columns, \"Missing subject column\"\n",
    "    assert len(set(includes) - set(columns)) == 0, \"Missing includes\"\n",
    "    assert depvar in columns, 'Missing depvar'\n",
    "\n",
    "    if average_unused:\n",
    "        if agg == 'mean':\n",
    "            temp = temp.groupby([subject] + effects + includes).mean().reset_index()\n",
    "        else:\n",
    "            temp = temp.groupby([subject] + effects + includes).median().reset_index()\n",
    "    labels_dict = unique_labels(temp, effects)\n",
    "    if len(includes) != 0:\n",
    "        labels_dict.update(unique_labels(temp, includes))\n",
    "    mask = [True if i in effects else False for i in labels_dict.keys()]\n",
    "    mask_conds = [True for i in range(len(mask))]\n",
    "    inds = compress(range(len(mask)), mask)\n",
    "    \n",
    "    labels = [i for i in labels_dict.keys()]\n",
    "    cc = [i for i in labels_dict.values()]\n",
    "    used_cc = compress(cc, mask)\n",
    "    stat = []\n",
    "    ps = []\n",
    "    index = []\n",
    "    for ind, c in zip(inds, used_cc):\n",
    "        mask_conds[ind] = False\n",
    "        cc_temp = list(compress(cc, mask_conds))\n",
    "        # print(mask_conds)\n",
    "        # print(cc)\n",
    "        # print(list(cc_temp))\n",
    "        for x1, x2 in combinations(c, 2):\n",
    "            if len(cc_temp) > 1:\n",
    "                mesh = true_meshgrid(*cc_temp).tolist()\n",
    "            else:\n",
    "                mesh = np.array(cc_temp).T.tolist()\n",
    "            for label in mesh:\n",
    "                l1, l2 = label.copy(), label.copy()\n",
    "                l1.insert(ind, x1)\n",
    "                l2.insert(ind, x2)\n",
    "                query_a = \" and \".join([f'{cond_name} == \"{cond}\"' for cond_name, cond in zip(labels, l1)])\n",
    "                query_b = \" and \".join([f'{cond_name} == \"{cond}\"' for cond_name, cond in zip(labels, l2)])\n",
    "                a = temp.query(query_a)[depvar]\n",
    "                b = temp.query(query_b)[depvar]\n",
    "                pval, statistic = stats.ttest_rel(a, b, nan_policy='omit').pvalue, stats.ttest_rel(a, b, nan_policy='omit').statistic\n",
    "                stat.append(statistic), ps.append(pval)\n",
    "                index.append([labels[ind]] + label + [x1, x2])\n",
    "        mask_conds[ind] = True\n",
    "    res_df = pd.DataFrame([stat, ps]).T\n",
    "    # print(index)\n",
    "    res_df.index = pd.MultiIndex.from_tuples(index)\n",
    "    res_df.columns = ['Statistic', 'P value']\n",
    "    res_df['Holmes corr'] = fdr(res_df['P value'])\n",
    "    res_df.index.names = ['Effect'] + [i for i in range(len(label))] + ['A', 'B']\n",
    "    # res_df.style.apply(lambda x: [\"background: red\" if v > 0.05 and if  else \"\" for v in x], axis = 1)\n",
    "    res_df\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = postHocTtest(dfs[\"ClustCoef\"]['relative'], effects=['Day', 'Session'], includes=['Band'])\n",
    "df.style.apply(lambda x: [\"background-color: red\" \n",
    "                          if (i >= 1 and v < 0.05)\n",
    "                          else \"\" for i, v in enumerate(x)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdata([4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
